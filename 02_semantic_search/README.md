# LLM을 이용한 의미 기반 검색

## 비대칭적 의미 기반 검색
- 비대칭(asymmetric) 부분은 입력 쿼리의 의미 정보와 검색 시스템이 검색해야 하는 문서/정보 사이에 불균형이 있따는 사실을 의미한다.

**의미 기반 검색 시스템**
- 사용자 쿼리의 의미와 맥락을 이해하고, 이를 검색 가능한 문서의 의미 및 맥락과 대조할 수 있다.
- 정확한 키워드나 n-gram 일치에 의존하지 않고도 데이터베이스에서 관련된 결과를 찾아낼 수 있으며, 사전 훈련된 LLM을 이용하여 쿼리와 문서/정보의 뉘앙스를 이해한다.

</br>

## 구성 요소
### 텍스트 임베더(Text Embedder)
- 텍스트 문서나 단어 또는 구문을 받아 벡터로 변환한다. 이 벡터는 입력된 텍스트마다 고유하며 구문의 맥락적 의미를 포착해야 한다.

**무엇이 텍스트를 '유사'하게 만드는가**
- 코사인 유사도(Cosine Similarity) : 두 벡터가 얼마나 유사한지를 측정하는 방법.
    - 두 벡터 사이의 각도를 살펴보고, 방향이 얼마나 가까운지에 따라 점수를 매긴다.
        - 같은 벡터 방향 : 1
        - 수직 : 0
        - 반대 방향 : -1
    - 벡터의 크기는 중요하지 않고 방향만 중요하다.
- 내적(Dot product), 유클리드 거리(Euclidean distance) 또한 선택지가 될 수 있다.
- 크기가 1인 정규화된 벡터를 사용하는 경우
    - 코사인 유사도가 내적과 동일
    - 코사인 유사도와 유클리드 거리는 동일한 순위의 결과를 가져옴

### 문서 청킹(Document Chunking)
- 큰 문서를 임베딩하기 위해 더 작고 관리 가능한 청크로 나누는 것

**최대 토큰 범위 분할(Max Token Window Chunking)**
- 주어진 최대 크기의 청크로 문서를 나누는 것

**맞춤형 구분 기호 찾기**
- 청킹 방법을 돕기 위해, PDF에서의 페이지 분리나 단락 사이의 새로운 줄과 같은 맞춤형 자연 구분 기호를 찾을 수 있다.
- 주어진 문서에 대해, 텍스트 내의 자연스러운 공백을 식별하고, 이를 사용하여 결국 임베딩되는 청크에 들어갈 더 의미 있는 텍스트 단위를 생성할 수 있게 된다.

**클러스터링을 사용하여 의미 기반 문서 생성하기**
- 의미적으로 유사한 작은 정보 청크를 결합하여 새로운 문서를 생성하는 것

**청크로 나누지 않고 전체 문서 사용하기**
- 가장 쉬운 옵션이지만, 문서가 너무 길어 텍스트를 임베딩할 때 문맥 윈도우 한계에 도달하는 경우 단점이 된다.


### 벡터 데이터베이스(Vector Database)
- 벡터를 빠르게 저장하고 검색하기 위해 특별히 설계된 데이터 저장 시스템
- 문서나 문서 일부의 의미를 인코딩하고 저장하는 LLM에 의해 생성된 임베딩을 저장하는 데 유용
- 최근접 이웃 탐색을 효율적으로 수행할 수 있음


### 파인콘(Pinecone)
- 소규모, 중규모의 데이터셋을 위해 설계된 벡터 데이터베이스
- 빠른 벡터 검색과 검색에 최적화되어 있어 낮은 대기시간이 필요한 애플리케이션에 좋은 선택


### 검색 결과 재순위화(re-ranking)
- 유사도 비교 후 사용자에게 가장 관련된 결과가 제시되도록 순위를 다시 지정해주는 것

**크로스-인코더(Cross-Encoder) 사용**
- 입력 시퀀스 쌍을 취하고 두 번째 시퀀스가 첫 번째에 얼마나 관련이 있는지를 점수로 예측하는 트랜스포머 모델의 한 유형
- 개별 키워드만이 아닌 전체 쿼리의 문맥을 고려할 수 있음

### API

**FastAPI**
- 빠르게 파이썬으로 API를 구축하기 위한 웹 프레임워크