# Large Language Model(LLM)
- 대규모 언어 모델(LLM)은 대부분 **트랜스포머 아키텍처**에서 파생된 AI 모델이며, 언어, 코드 등을 이해하고 생성하기 위해 설계되었다.
- 방대한 양의 텍스트 데이터로 학습이 되어서 사람의 언어나 복잡성, 뉘앙스 등을 잘 포착할 수 있다.
- 의료, 금융 등의 다양한 산업과 응용 분야에서 점점 더 가치가 상승하고 있다.

**자기회귀 언어 모델(Autoregressive Language Model)**
- 문장에서 이전 토큰만을 기반으로 다음 토큰을 예측하도록 훈련된다.
- 트랜스포머 모델의 디코더 부분에 해당된다. ex) GPT

**자동 인코딩 언어 모델(Autoencoding Language Model)**
- 손상된 버전의 입력 내용으로부터 기존 문장을 재구성하도록 훈련된다.
- 전체 문장의 양방향 포연을 생성한다.
- 트랜스포머 모델의 인코더 부분에 해당된다. ex) BERT

<br/>

## LLM 주요 특징
---
**Transformer**
- Sequence-to-Sequence(seq2seq) 모델
    - 인코더(Encoder)
        - 입력 텍스트를 받아들여 핵심 구성 요소로 분리하고, 해당 구성 요소를 벡터로 변환하는 업무 담당
        - 어텐션을 사용하여 텍스트의 맥락 이해
    - 디코더(Decoder)
        - 수정된 형식의 어텐션을 사용하여 다음에 올 최적의 토큰을 예측하여 텍스트 생성

**일반적인 LLM의 세 가지 주요 카테고리**
1. 자기회귀 모델
    - 이전 토큰을 기반으로 문장의 다음 토큰을 예측
    - 주어진 맥락을 따라서 일관성 있는 텍스트 생성에 효과적
    - GPT
2. 자동 인코딩 모델
    - 입력 토큰 중 일부를 가리고 남아있는 토큰으로부터 그것들을 예측하여 문맥을 양방향으로 이해하여 표현을 구축
    - 토큰 간의 맥락적 관계를 빠르고 대규모로 포착하는 데 능숙
    - BERT
3. 자기회귀와 자동 인코딩의 조합
    - 추가 맥락을 포착하는 능력이 좋은 인코더의 능력을 통해 순수한 디코더 기반의 자기회귀 모델보다 여러 가지 문맥에서 더 다양하고 창의적인 텍스트 생성
    - T5

**더 많은 문맥 제공**
- LLM이 어떻게 구성되던지 간에 모든 LLM은 문맥에 신경쓴다.
- 2013년 Word2vec가 도입된 이래로 의미와 문맥을 결합하여 가장 의미 있는 토큰 임베딩을 만들 수 있는 가장 좋은 방법을 찾았다.
- 트랜스포머는 어텐션 계산을 이용해서 이 조합을 현실로 만들었다.

<br/>

## LLM 작동 원리
---
**사전 훈련(Pre-training)**
- LLM은 대량의 텍스트 데이터로 특정 언어 모델링 관련 작업에 대해 사전 훈련되었다.
- LLM은 사전 훈련 중에 일반적인 언어와 단어 간의 관계를 배우고 이해하려고 한다. 모든 LLM은 서로 다른 말뭉치와 서로 다른 작업에 대해서 훈련되었다.
- LLM의 사전 훈련 과정은 연구자들이 시간을 들여 LLM을 더 잘 훈련시키는 방법을 찾아내고 크게 도움이 되지 않는 방법을 단계적으로 제거함에 따라 발전한다.

**전이학습(Transfer Learning)**
- 머신러닝에서 한 작업에서 얻은 지식을 활용하여 다른 관련 작업의 성능을 향상시키는 기술
- LLM에 대한 전이학습은 텍스트 데이터의 한 말뭉치에서 사전 훈련된 LLM을 가져온 뒤, 텍스트 분류나 텍스트 생성과 같은 특정 작업을 위해 작업 특정 데이터로 모델의 파라미터를 업데이트함으로써 모델을 파인튜닝하는 것을 포함한다.
- 전이학습을 통해 처음부터 모델을 훈련시키는데 필요한 시간과 자원을 크게 줄일 수 있다.

**파인튜닝(Fine-tuning)**
- LLM을 작업에 특화된 상대적으로 작은 크기의 데이터셋에서 훈련시켜, 특정 작업을 위한 파라미터를 조정하는 것

**어텐션(Attention)**
- 트랜스포머만이 아니라 다양한 가중치를 입력의 다른 부분에 할당하는 딥러닝 모델에서 사용되는 메커니즘
- 모델이 동적으로 입력의 다른 부분에 '집중'할 수 있게 하여, 가장 중요한 정보를 우선시하고 강조할 수 있다.

**임베딩(Embedding)**
- 고차원 공간에서의 단어, 구절, 또는 토큰의 수하적 표현
- 자연어 처리에서의 임베딩은 다른 단어와의 의미와 관계를 포착하는 방식

**토큰화(Tokenization)**
- 텍스트를 가장 작은 이해 단위인 토큰으로 분해하는 과정
- 토큰들은 의미를 내포한 정보 조각이며, 어텐션 계산에 입력으로 사용되어 LLM이 실제로 학습하고 작동하게 된다.

**인간 피드백 기반 강화 학습(Reinforcement Learning for Human Feedback, RLHF)**
- LLM에 그 자체의 출력을 상대적으로 작고 고품질의 피드백 단계(사람)에서 학습하게 하여, 전통적인 지도 학습의 일부 한계를 극복하게 한다.

<br/>

## 도메인 특화 LLM(Domain-Specific LLM)
- 생물학이나 금융과 같은 특정 주제 영역에서 훈련된 LLM
- 일반 목적의 LLM보다 상대적ㅇ로 좁지만, 해당 도메인에서 사용되는 언어와 개념을 더 잘 이해하여 특정 도메인 내의 NLP 작업에 대한 정확도와 유창성이 향상된다.