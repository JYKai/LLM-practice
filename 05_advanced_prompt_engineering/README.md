# Advanced Prompt Engineering

**목표**  
프롬프트를 향상시키고, 성능을 최적화하며, LLM 기반 애플리케이션의 보안 강화

</br>

## 프롬프트 인젝션(Prompt Injection) 공격

### 프롬프트 인젝션
공격자가 LLM에 제공된 프롬프트를 조작하여 편향된 또는 악의적인 결과를 생성하려고 할 때 사용하는 공격 유형
- 민감하거나 고위험 애플리케이션에서 사용되는 LLM에 중대한 문제가 될 수 있음.
- 혼란스럽고 모순적인 명령으로 LLM을 속여 기존의 프롬프트를 공개하도록 만들어 경쟁 애플리케이션의 프롬프트를 훔칠 수 있음.

**프롬프트 인젝션 방지**  
1. 지나치게 짧은 프롬프트는 되도록 피한다.
2. 추측하기 어려운 독특하고 복잡한 프롬프트 구조를 사용한다.
3. 입력/출력 유효성 검사 기술을 사용함으로써 공격 패턴의 가능성을 사전에 필터링하며, 후처리 단계에서 민감한 정보를 포함하는 답변을 필터링한다.
4. 프롬프트를 정기적으로 업데이트하고 수정한다.

### 입력/출력 유효성 검사
LLM용 프롬프트를 설계할 때 다양한 유형의 시나리오를 고려하고 잠재적 취약성에 대비하기 위해 적절한 보호 조치를 구현하는 것이 중요하다.

**LLM BART**  
Meta AI에 의 만들어진 LLM BART는 멀티 장르 자연어 추론(Multi-Genre Natural Language Inference, MLNI) 데이터셋으로 학습되어 LLM에서 생성된 출력에서 공격적인 행동을 감지하고 필터링하는데 사용된다.
- 주요 LLM에서 출력을 얻은 후 BART-MNLI를 사용하여 생성된 답변과 미리 정의된 부적절한 키워드, 구문 또는 개념 목록을 비교한다.