# 맞춤형 파인튜닝(Fine-tuning)으로 LLM을 최적화하기
**파인튜닝**  
파인튜닝은 이미 만들어진 모델을 업데이트해서 더 높은 품질의 결과를 만든다.
- 사용하는 토큰을 절약하고, 더 빠른 답변을 만들 수 있다.
- 장기적으로 비용을 절역하는 데 매우 효과적이다.

## 파인튜닝과 전이학습(Transfer Learning)
파인 튜닝은 전이학습을 기반으로 한다. 

**전이학습**은 사전 훈련된 모델을 활용해 새로운 작업이나 분야에 기존 지식을 적용하는 기술이다.

**파인튜닝**은 사전 훈련된 모델의 파라미터들을 '최종'목표 작업에 더 잘 맞게 조정하는 전이학습의 특별한 형태이다.

### 파인튜닝 과정
1. 레이블이 지정된 데이터 수집
2. 하이퍼파라미터 선택
3. 모델 적응
4. 평가와 반복
5. 모델 구현 및 추가 학습

### 파운데이션 모델로 사전 훈련된 closed 소스 모델 사용
사전 훈련된 LLM은 전이학습과 파인튜닝에서 중요한 역할을 하며, 일반 언어의 이해와 지식의 기초를 제공한다.

**OpenAI의 파인튜닝 인프라를 사용하는 이점**
- 광범위하고 다양한 데이터셋에서 훈련된 GPT-4와 같은 강력한 사전 훈련 모델에 접근할 수 있다.
- 다양한 수준의 전문 지식을 가진 사람들을 위해 파인튜닝 과정을 단순화시킨 비교적 사용자 친화적인 인터페이스가 존재한다.
- 하이퍼파라미터를 선택하는 지침, 맞춤 예시를 준비하는 팁, 모델 평가에 대한 조언 등 파인튜닝 과정을 최적화하는 데 도움이 되는 다양한 도구와 자원이 있다.

</br>

## OpenAI 파인튜닝 API 살펴보기
GPT-3 API는 개발자들에게 진보된 LLM 중 하나에 대한 접근을 제공한다.

### 사례 연구: Amazon 리뷰 감정 분류
amazon_review_multi 데이터셋을 사용하여, 리뷰들에 감정 분류를 수행할 수 있도록 OpenAI의 사전 훈련된 모델을 파인튜닝 한다.
- review_title: 리뷰의 텍스트 제목
- review_body: 리뷰의 텍스트 본문
- starts: 1과 5 사이의 정수로 별점을 나타냄

### 데이터에 대한 지침 및 모범 사례
파인튜닝을 위한 데이터를 선택할 때 고려해야 할 몇 가지 사항
- 데이터 품질
- 데이터 다양성
- 데이터 균형
- 데이터 양

</br>

## OpenAI CLI로 맞춤형 예제 준비
파인튜닝을 시작하기 전에, API의 요구사항에 따라 데이터를 정리하고 형식을 맞추어 데이터를 준비해야 한다.
- 중복 제거
    - 모델이 특정 예제에 과적합되는 것을 방지
    - 새로운 데이터에 대한 일반화 능력 향상
- 데이터 분할
    - 훈련, 검증, 테스트셋으로 나누어, 각 셋에 예제의 무작위 분포를 유지한다.
- 훈련 데이터 섞기
    - 데이터 편향 감소
    - 훈련 예제를 기억하는 대신 기본 패턴을 학습하는 데 집중할 가능성을 높여 과적합을 방지
- OpenAI JSONL 형식 생성
    - OpenAI의 API는 훈련 데이터가 JSONL(JSON Lines, 개행으로 구분된 JSON) 형식으로 되었을 때 더 좋은 성능은 낸다.
    - 훈련 및 검증셋의 각 예제에 대해 'prompt(입력)'와 'completion(타겟클래스)'이라는 두 필드를 가지는 JSON 객체를 생성한다.

데이터셋 내 완성 토큰에 대해, 분류 레이블 앞에는 시작 공백이 있어야 한다. 이렇게 하면 모델이 새 토큰을 생성해야 한다는 것을 이해할 수 있다.

모델을 파인튜닝하는 과정에서 프롬프트를 준비할 때, 모델은 이미 특정 작업에 대한 데이터로 파인튜닝되었기 때문에 몇 가지 예시를 포함할 필요가 없다.

대신 리뷰 텍스트와 필요한 모든 맥락을 포함한 프롬프트를 제공한 후, 원하는 출력 형식을 나타내는 접미사('₩n₩n###₩n₩n')을 추가한다.
- 프롬프트는 가능한 짧아야 한다. 퓨삿이나 지시가 필요하지 않다.
- 프롬프트 끝에 있는 접미사(예: '₩n₩n###₩n₩n')가 있으면 GPT는 답변을 예측할 때라는 것을 알게 된다.
- 분류 값 앞에 띄어쓰기가 있으면 GPT는 새 토큰을 예측해야 한다는 것을 알게 된다.